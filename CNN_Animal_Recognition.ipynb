{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "592pPdWMi-YX"
      },
      "source": [
        "# Definição do Problema\n",
        "\n",
        "## Objetivo\n",
        "\n",
        "Por meio de redes neurais artificiais convolucionais (CNNs), busca-se realizar classificação multiclasse de imagens contendo diferentes animais.\n",
        "\n",
        "## Conjunto de dados\n",
        "\n",
        "O conjunto pode ser obtido [aqui](https://www.kaggle.com/datasets/alessiocorrado99/animals10).\n",
        "\n",
        "Há dez tipos distintos de animais, sendo eles o cão, o cavalo, o elefante, a borboleta, a galinha, o gato, a vaca, a ovelha, a aranha e o esquilo, cada qual contendo suas respectivas variantes macho e fêmea. Trata-se de um conjunto com cerca de 26k exemplos, previamente rotulados, homogeneamente distribuído entre sete das dez classes, enquanto três delas apresentam quantia de instâncias significativamente superior às demais (vide gráfico na seção de \"Leitura do conjunto de dados\"). Ainda, em relação à composição desses dados, os exemplos se caracterizam, disjuntamente, como imagens conceituais, fotos, pinturas digitais e demais tipos visuais, embora a distribuição seja desconhecida para esse caso -- dada a falta de rotulação nesse sentido.\n",
        "\n",
        "A saber, as imagens capturam os animais em diferentes ângulos, por vezes priorizando uma ou outra característica deles -- como, por exemplo, as asas para a borboleta, e as patas de um elefante, que visualmente se diferem em relação aos corpos dos demais animais. Além disso, algumas imagens contêm diversas ocorrências de um mesmo animal, como uma foto contendo uma ninhada de cães. Quanto aos planos de fundo, não há constância para as classes, de tal maneira que se torne seguro classificar tais animais sem ter de recorrer à análise do ambiente para isso; por exemplo, há fotos de esquilos em árvores e em solos coberto por folhas, mas também em ambientes urbanos e em telas planas.\n",
        "\n",
        "Por fim, a divisão do conjunto de dados é realizada de forma pseudoaleatória, com semente fixa, por meio da técnica de Holdout. Desse modo, o referido conjunto é dividido nos subconjuntos de treino, de validação e de teste, cada qual com 80%, 10% e 10% da quantia absoluta de exemplos respectivamente. Para tanto, uma ferramenta utilitária do Keras será utilizada.\n",
        "\n",
        "## Conceituação\n",
        "\n",
        "Trata-se de um problema de classificação multiclasse por meio de aprendizado supervisionado. Ainda, por utilizar redes neurais artificiais, caracteriza-se como um paradigma conexionista, que será descrito por instâncias e aprenderá de forma incremental. Por conseguinte, não há descrição por meio de tabelas atributo-valor: ao invés disso, as características dos dados serão seus três canais (RGB), que são representados por matrizes de pixels, de modo aos modelos neurais inferirem novas características e realizarem o processo classificativo a partir de suas hipóteses.\n",
        "\n",
        "## Plano de execução\n",
        "\n",
        "Após a leitura e o pré-processamento dos dados, serão treinados cinco diferentes modelos neurais: um modelo denso, um modelo convolucional com poucas camadas, e as arquiteturas Xception, ResNet50 e InceptionV3. Para cada modelo, serão tomados os resultados que, ao final, serão comparados entre si. Ainda, será feita uma abordagem de visualização para compreensão do modo de extração de características por parte dos modelos convolucionais.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "25SS833iEqGC"
      },
      "source": [
        "# Aquisição do conjunto de dados\n",
        "\n",
        "Para execução em ambiente Google Colaboratory.\n",
        "\n",
        "Para execução local, faça o download e o desempacotamento da base de dados no diretório deste notebook, \n",
        "no interior de uma pasta denominada \"data\". Caso não exista, crie uma. Ao final, é necessário que os \n",
        "dados estejam em ./data/raw-img/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9WWr0ixqEiE7"
      },
      "outputs": [],
      "source": [
        "# Download do pacote do Kaggle\n",
        "! pip install -q kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1PKCz31VE3jX"
      },
      "outputs": [],
      "source": [
        "# Em sua conta do Kaggle, gere uma chave de API: isso fornecerá \n",
        "# um arquivo \"kaggle.json\". Faça upload dele nesta célula\n",
        "from google.colab import files\n",
        "files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KL4xA4lXFFzw"
      },
      "outputs": [],
      "source": [
        "# Processamento da licença\n",
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w7j-OyXEJhcI",
        "outputId": "0ba8c945-8000-4cf2-a5e1-ffb869f7328f"
      },
      "outputs": [],
      "source": [
        "# Importação do conjunto de dados\n",
        "! kaggle datasets download 'alessiocorrado99/animals10'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3VQv2mzUJmMP"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "\n",
        "# Unzip dos dados\n",
        "! mkdir data\n",
        "! unzip animals10.zip -d data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PcUouc2zOakv"
      },
      "source": [
        "# Dependências"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oJmDKWUlOdCj"
      },
      "outputs": [],
      "source": [
        "# Para ciência de dados\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.models import Model, save_model, load_model\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Manipulação de arquivos\n",
        "import os\n",
        "\n",
        "# Para mostrar gráficos e imagens\n",
        "from matplotlib import pyplot as plt\n",
        "from IPython.display import Image, display\n",
        "plt.style.use(\"bmh\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OYvvPFE9MeMd",
        "outputId": "99bffcef-1cd2-4120-a9ad-75c54452b915"
      },
      "outputs": [],
      "source": [
        "# Verifica se a GPU está sendo utilizada e aplica a expansão memorial\n",
        "physical_devices = tf.config.experimental.list_physical_devices(\"GPU\")\n",
        "print(\"Quantia de GPUs disponíveis:\", len(physical_devices))\n",
        "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7up8o6LUL8Vb"
      },
      "source": [
        "# Leitura do conjunto de dados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8iopPQ7eWVCX"
      },
      "outputs": [],
      "source": [
        "# Tradução de nomes presente em \"./data/translate.py\"\n",
        "translation_mapper = {\n",
        "    \"cane\": \"dog\", \n",
        "    \"cavallo\": \"horse\", \n",
        "    \"elefante\": \"elephant\", \n",
        "    \"farfalla\": \"butterfly\", \n",
        "    \"gallina\": \"chicken\", \n",
        "    \"gatto\": \"cat\", \n",
        "    \"mucca\": \"cow\", \n",
        "    \"pecora\": \"sheep\", \n",
        "    \"ragno\": \"spider\",\n",
        "    \"scoiattolo\": \"squirrel\"\n",
        "}\n",
        "\n",
        "# Para mapeamento das labels\n",
        "label_mapper = dict([(name, idx) for idx, name in enumerate(translation_mapper)])\n",
        "label_unmapper = dict([(idx, name) for idx, name in enumerate(translation_mapper.values())])\n",
        "\n",
        "# Diretório das imagens\n",
        "IMG_DIR_PATH = \"./data/raw-img/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        },
        "id": "7Ej8qnkfxEtj",
        "outputId": "b03f2506-2352-46c6-e725-d8411db5360a"
      },
      "outputs": [],
      "source": [
        "# Visualização da distribuição de classes\n",
        "class_names = os.listdir(IMG_DIR_PATH)\n",
        "class_sizes = []\n",
        "for class_name in class_names:\n",
        "    class_sizes.append(len(os.listdir(IMG_DIR_PATH + class_name)))\n",
        "class_names = list(map(translation_mapper.get, class_names))\n",
        "plt.figure(figsize=(10,6))\n",
        "x = np.arange(len(class_names))\n",
        "plt.bar(x, class_sizes)\n",
        "plt.xticks(x, class_names)\n",
        "plt.show()\n",
        "print(\"Total de elementos: {}\".format(np.sum(class_sizes)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cbqduTZAMPM5",
        "outputId": "271ce637-2813-4053-ac43-1fb549aa7c28"
      },
      "outputs": [],
      "source": [
        "# Para manipulação dos dados\n",
        "SEED = 16\n",
        "IMAGE_SIZE = (224, 224)\n",
        "load_dataset = lambda subset, split: tf.keras.utils.image_dataset_from_directory (\n",
        "    IMG_DIR_PATH,\n",
        "    labels=\"inferred\",\n",
        "    label_mode=\"int\",\n",
        "    class_names=None,\n",
        "    color_mode=\"rgb\",\n",
        "    batch_size=32,\n",
        "    image_size=IMAGE_SIZE,\n",
        "    shuffle=True,\n",
        "    seed=SEED,\n",
        "    subset=subset, \n",
        "    validation_split=split, \n",
        ")\n",
        "train_data = load_dataset(\"training\", 0.2)\n",
        "val_data = load_dataset(\"validation\", 0.2)\n",
        "train_size = len(train_data.file_paths)\n",
        "test_size = int(len(val_data.file_paths)/2)\n",
        "test_data = val_data.take(test_size)\n",
        "val_data.skip(test_size)\n",
        "val_size = test_size\n",
        "print(\"\\nUsing {}, {} and {} files for training, validation and test respectively.\".format(train_size, val_size, test_size))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 592
        },
        "id": "fASccnl_PjRJ",
        "outputId": "ede817fc-114c-4dbb-d2bf-b5c95fab532d"
      },
      "outputs": [],
      "source": [
        "# Exemplo de imagens (possivelmente distorcidas devido ao redimensionamento)\n",
        "plt.figure(figsize=(10, 10))\n",
        "for images, labels in train_data.take(1):\n",
        "    for i in range(9):\n",
        "        ax = plt.subplot(3, 3, i + 1)\n",
        "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "        plt.title(label_unmapper[int(labels[i])])\n",
        "        plt.axis(\"off\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jyVCZcNmZBbU"
      },
      "source": [
        "# Treinamento dos modelos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qQ1RsCztz-eM"
      },
      "outputs": [],
      "source": [
        "# Função de perda e otimizador a serem utilizados\n",
        "from keras.losses import SparseCategoricalCrossentropy\n",
        "from keras.optimizers import Adam, SGD\n",
        "\n",
        "# Para mapeamento\n",
        "DENSE = \"d\"\n",
        "CONVOLUTIONAL = \"c\"\n",
        "XCEPTION = \"x\"\n",
        "RESNET50 = \"r\"\n",
        "INCEPTIONV3 = \"i\"\n",
        "\n",
        "# Para guardas os resultados\n",
        "results = {}\n",
        "\n",
        "# Caminhos para os modelos salvos\n",
        "model_paths = {\n",
        "    DENSE: \"./models/dense_model.h5\",\n",
        "    CONVOLUTIONAL: \"./models/conv_model.h5\", \n",
        "    XCEPTION: \"./models/xception_model.h5\", \n",
        "    RESNET50: \"./models/resnet50.h5\", \n",
        "    INCEPTIONV3: \"./models/inceptionv3_model.h5\", \n",
        "}\n",
        "model_backup_paths = {\n",
        "    DENSE: \"./models/backups/dense_model.h5\",\n",
        "    CONVOLUTIONAL: \"./models/backups/conv_model.h5\", \n",
        "    XCEPTION: \"./models/backups/xception_model.h5\", \n",
        "    RESNET50: \"./models/backups/resnet50.h5\", \n",
        "    INCEPTIONV3: \"./models/backups/inceptionv3_model.h5\", \n",
        "}\n",
        "\n",
        "# Tensor de entrada\n",
        "input_tensor = keras.layers.Input(shape=(*IMAGE_SIZE, 3))\n",
        "\n",
        "# Quantia de classes\n",
        "num_classes = len(label_mapper)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpKNaIW5ZHlt"
      },
      "source": [
        "## Baseline: RNA densa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lq1i1J7MYUiw",
        "outputId": "6e95583e-f6a3-4f5a-f00d-26fcaffe0da1"
      },
      "outputs": [],
      "source": [
        "# Camadas necessárias\n",
        "from keras.layers import Input, Flatten, Dense\n",
        "\n",
        "# Criação do modelo\n",
        "def create_dense_model(input_tensor, num_labels, loss, optimizer, name=\"model\"):\n",
        "\n",
        "    # Entrada\n",
        "    inputs = input_tensor\n",
        "\n",
        "    # Camadas Densas\n",
        "    x = Flatten()(inputs[:,:,0]) # Para não explodir a memória: uso do primeiro canal somente\n",
        "    x = Dense(units=256, activation=\"relu\")(x)\n",
        "    x = Dense(units=128, activation=\"relu\")(x)\n",
        "    x = Dense(units=64, activation=\"relu\")(x)\n",
        "    outputs = Dense(units=num_labels, activation=\"softmax\")(x)\n",
        "\n",
        "    # Finalização\n",
        "    model = Model(inputs=inputs, outputs=outputs, name=name)\n",
        "    model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Modelo Denso\n",
        "dense_model = None\n",
        "if not os.path.exists(model_paths[DENSE]):\n",
        "    loss_function = SparseCategoricalCrossentropy()\n",
        "    model_optimizer = Adam(learning_rate = 0.00025, clipnorm = 1.0)\n",
        "    dense_model = create_dense_model(input_tensor, num_classes, loss_function, model_optimizer, name=\"dense_model\")\n",
        "else:\n",
        "    dense_model = load_model(model_paths[DENSE])\n",
        "\n",
        "# Sumarização\n",
        "dense_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nOk7s0t8dDve",
        "outputId": "00cc18ba-6da2-45eb-d31d-653bacabddbf"
      },
      "outputs": [],
      "source": [
        "# Treino\n",
        "epochs = 6\n",
        "dense_model.fit (\n",
        "    train_data, \n",
        "    validation_data = val_data, \n",
        "    epochs = epochs, \n",
        ")\n",
        "save_model(dense_model, model_backup_paths[DENSE])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V8bbNcBQicPE",
        "outputId": "b297f2d6-9356-4f84-e7f0-d595eba5690e"
      },
      "outputs": [],
      "source": [
        "# Teste\n",
        "results[DENSE] = dense_model.evaluate(test_data)\n",
        "print(\"loss = {:.2f}; accuracy = {:.2f}%\".format(results[DENSE][0], results[DENSE][1] * 100.0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Salvar modelo\n",
        "save_model(dense_model, model_paths[DENSE])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7QUB6NsYv9Nl"
      },
      "source": [
        "## Modelo Convolucional"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P8ya0kPvwhRH",
        "outputId": "27439743-d03f-430a-c696-11ad43d8ca6a"
      },
      "outputs": [],
      "source": [
        "# Camadas necessárias\n",
        "from keras.layers import Input, Activation, Conv2D, MaxPooling2D, Dropout, Flatten, Dense\n",
        "\n",
        "# Criação do modelo\n",
        "def create_conv_model(input_tensor, num_labels, loss, optimizer, name=\"model\"):\n",
        "\n",
        "    # Entrada\n",
        "    inputs = input_tensor\n",
        "\n",
        "    # Primeira seção\n",
        "    x = Conv2D(32, kernel_size=(3, 3), padding='same')(inputs)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Conv2D(32,kernel_size=(3, 3))(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "    x = Dropout(0.25)(x)\n",
        "\n",
        "    # Segunda seção\n",
        "    x = Conv2D(64, kernel_size=(3, 3), padding='same')(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Conv2D(64, kernel_size=(3, 3))(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "    x = Dropout(0.25)(x)\n",
        "\n",
        "    # Seção final\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(512)(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    x = Dense(num_labels)(x)\n",
        "    outputs = Activation(tf.nn.softmax)(x)\n",
        "\n",
        "    # Finalização\n",
        "    model = Model(inputs=inputs, outputs=outputs, name=name)\n",
        "    model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Modelo convolucional\n",
        "conv_model = None\n",
        "if not os.path.exists(model_paths[CONVOLUTIONAL]):\n",
        "    loss_function = SparseCategoricalCrossentropy()\n",
        "    model_optimizer = Adam(learning_rate = 0.00025, clipnorm = 1.0)\n",
        "    conv_model = create_conv_model(input_tensor, num_classes, loss_function, model_optimizer, name=\"conv_model\")\n",
        "else:\n",
        "    conv_model = load_model(model_paths[CONVOLUTIONAL])\n",
        "\n",
        "# Sumarização\n",
        "conv_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "pc-6rPlAlniT",
        "outputId": "e9d8cd4a-1108-4872-82a4-eca6878219d4"
      },
      "outputs": [],
      "source": [
        "# Treino\n",
        "epochs = 12\n",
        "conv_model.fit (\n",
        "    train_data, \n",
        "    validation_data = val_data, \n",
        "    epochs = epochs, \n",
        ")\n",
        "save_model(conv_model, model_backup_paths[CONVOLUTIONAL])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-L2NqYo9wASG",
        "outputId": "2ecce56b-b207-4878-b169-c436615c8844"
      },
      "outputs": [],
      "source": [
        "# Teste\n",
        "results[CONVOLUTIONAL] = conv_model.evaluate(test_data)\n",
        "print(\"loss = {:.2f}; accuracy = {:.2f}%\".format(results[CONVOLUTIONAL][0], results[CONVOLUTIONAL][1] * 100.0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Salvar modelo\n",
        "save_model(conv_model, model_paths[CONVOLUTIONAL])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a5CHvUi4oz4Y"
      },
      "source": [
        "## Modelos pré-definidos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SRCjJ56Oyy1W"
      },
      "outputs": [],
      "source": [
        "# Camadas necessárias para a transferência de aprendizado\n",
        "from keras.layers import Dense, GlobalAveragePooling2D\n",
        "\n",
        "# Modelos originais\n",
        "from keras.applications.xception import Xception\n",
        "from keras.applications.resnet import ResNet50\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "\n",
        "# Pré-processamento\n",
        "from keras.applications.xception import preprocess_input as xception_preprocess_input\n",
        "from keras.applications.resnet import preprocess_input as resnet_preprocess_input\n",
        "from keras.applications.inception_v3 import preprocess_input as inception_preprocess_input"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bq6gfFOexSXZ"
      },
      "source": [
        "### Xception"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Mapeamento dos conjuntos\n",
        "def xception_preprocess_dataset(images, labels): \n",
        "    return xception_preprocess_input(images), labels\n",
        "xception_train_data = train_data.map(xception_preprocess_dataset)\n",
        "xception_val_data = val_data.map(xception_preprocess_dataset)\n",
        "xception_test_data = test_data.map(xception_preprocess_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Nova arquitetura Xception"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VbxA2SqGxb8Q"
      },
      "outputs": [],
      "source": [
        "# Modelo original\n",
        "base_model = Xception(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "\n",
        "# Adição de camadas\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "outputs = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "# Novo modelo\n",
        "xception_model = Model(inputs=base_model.input, outputs=outputs)\n",
        "\n",
        "# Congelamento das camadas convolucionais (para treinar somente as últimas superiores)\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Compilação\n",
        "loss_function = SparseCategoricalCrossentropy()\n",
        "model_optimizer = Adam(learning_rate = 0.00025, clipnorm = 1.0)\n",
        "xception_model.compile(optimizer=model_optimizer, loss=loss_function, metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8JyE1kDUARkB",
        "outputId": "0545c451-b5fd-40ba-a342-e8ade82817d1"
      },
      "outputs": [],
      "source": [
        "# Treino das camadas superiores\n",
        "epochs = 8\n",
        "xception_model.fit (\n",
        "    xception_train_data, \n",
        "    validation_data = xception_val_data, \n",
        "    epochs = epochs, \n",
        ")\n",
        "save_model(xception_model, model_backup_paths[XCEPTION])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y3ii6iBkAS80",
        "outputId": "48d55d48-1bbb-4e12-b1c0-c5ab55e906bb"
      },
      "outputs": [],
      "source": [
        "# Visualização das camadas (para escolher até onde descongelar)\n",
        "for i, layer in enumerate(base_model.layers):\n",
        "   print(i, layer.name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nGuTGWh3ATUw",
        "outputId": "e3278283-0964-45b4-f0d2-5944c6d6669b"
      },
      "outputs": [],
      "source": [
        "# Descongelamento das orimeiras camadas\n",
        "for layer in xception_model.layers[:105]:\n",
        "   layer.trainable = False\n",
        "for layer in xception_model.layers[105:]:\n",
        "   layer.trainable = True\n",
        "\n",
        "# Recompilação\n",
        "loss_function = SparseCategoricalCrossentropy()\n",
        "model_optimizer = SGD(learning_rate=0.0001, momentum=0.9)\n",
        "xception_model.compile(optimizer=model_optimizer, loss=loss_function, metrics=['accuracy'])\n",
        "\n",
        "# Treino\n",
        "epochs = 24\n",
        "xception_model.fit (\n",
        "    xception_train_data, \n",
        "    validation_data = xception_val_data, \n",
        "    epochs = epochs, \n",
        ")\n",
        "save_model(xception_model, model_backup_paths[XCEPTION])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Carregamento de um modelo Xception"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Carregamento do modelo\n",
        "xception_model = load_model(model_paths[XCEPTION])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Treino\n",
        "epochs = 1\n",
        "xception_model.fit (\n",
        "    xception_train_data, \n",
        "    validation_data = xception_val_data, \n",
        "    epochs = epochs, \n",
        ")\n",
        "save_model(xception_model, model_backup_paths[XCEPTION])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Teste da Xception"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P0S2Pi3HAX4k",
        "outputId": "d03cb527-1111-4033-fe6b-e379ad6616ba"
      },
      "outputs": [],
      "source": [
        "# Teste\n",
        "results[XCEPTION] = xception_model.evaluate(xception_test_data)\n",
        "print(\"loss = {:.2f}; accuracy = {:.2f}%\".format(results[XCEPTION][0], results[XCEPTION][1] * 100.0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Salvar modelo\n",
        "save_model(xception_model, model_paths[XCEPTION])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qMKXShwTxlUg"
      },
      "source": [
        "### ResNet50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Mapeamento dos conjuntos\n",
        "def resnet_preprocess_dataset(images, labels): \n",
        "    return resnet_preprocess_input(images), labels\n",
        "resnet_train_data = train_data.map(resnet_preprocess_dataset)\n",
        "resnet_val_data = val_data.map(resnet_preprocess_dataset)\n",
        "resnet_test_data = test_data.map(resnet_preprocess_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Nova arquitetura ResNet50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VUUTsYRDxRvS"
      },
      "outputs": [],
      "source": [
        "# Modelo original\n",
        "base_model = ResNet50(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "\n",
        "# Adição de camadas\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "outputs = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "# Novo modelo\n",
        "resnet_model = Model(inputs=base_model.input, outputs=outputs)\n",
        "\n",
        "# Congelamento das camadas convolucionais (para treinar somente as últimas camadas)\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Compilação\n",
        "loss_function = SparseCategoricalCrossentropy()\n",
        "model_optimizer = Adam(learning_rate = 0.00025, clipnorm = 1.0)\n",
        "resnet_model.compile(optimizer=model_optimizer, loss=loss_function, metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oYET1sjN_Ewz",
        "outputId": "7fdaf76a-a5e0-4941-fa69-1ed0a92c90ae"
      },
      "outputs": [],
      "source": [
        "# Treino das camadas superiores\n",
        "epochs = 8\n",
        "resnet_model.fit (\n",
        "    resnet_train_data, \n",
        "    validation_data = resnet_val_data, \n",
        "    epochs = epochs, \n",
        ")\n",
        "save_model(resnet_model, model_backup_paths[RESNET50])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ykzRX7Lm_Hom",
        "outputId": "df05cbf6-1e0b-4e15-b158-cda75bbc678a"
      },
      "outputs": [],
      "source": [
        "# Visualização das camadas (para escolher até onde descongelar)\n",
        "for i, layer in enumerate(base_model.layers):\n",
        "   print(i, layer.name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bZuQ3nkL_JlU",
        "outputId": "d5d21862-14ce-4f89-909c-e54383264147"
      },
      "outputs": [],
      "source": [
        "# Descongelamento das orimeiras camadas\n",
        "for layer in resnet_model.layers[:154]:\n",
        "   layer.trainable = False\n",
        "for layer in resnet_model.layers[154:]:\n",
        "   layer.trainable = True\n",
        "\n",
        "# Recompilação\n",
        "loss_function = SparseCategoricalCrossentropy()\n",
        "model_optimizer = SGD(learning_rate=0.0001, momentum=0.9)\n",
        "resnet_model.compile(optimizer=model_optimizer, loss=loss_function, metrics=['accuracy'])\n",
        "\n",
        "# Treino\n",
        "epochs = 32\n",
        "resnet_model.fit (\n",
        "    resnet_train_data, \n",
        "    validation_data = resnet_val_data, \n",
        "    epochs = epochs, \n",
        ")\n",
        "save_model(resnet_model, model_backup_paths[RESNET50])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Carregamento de um modelo ResNet50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Carregamento do modelo\n",
        "resnet_model = load_model(model_paths[RESNET50])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Treino\n",
        "epochs = 1\n",
        "resnet_model.fit (\n",
        "    resnet_train_data, \n",
        "    validation_data = resnet_val_data, \n",
        "    epochs = epochs, \n",
        ")\n",
        "save_model(resnet_model, model_backup_paths[RESNET50])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Teste da ResNet50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJqhI3aJ_8wI",
        "outputId": "d6d86635-ce23-43fe-b446-6415683502e9"
      },
      "outputs": [],
      "source": [
        "# Teste\n",
        "results[RESNET50] = resnet_model.evaluate(test_data)\n",
        "print(\"loss = {:.2f}; accuracy = {:.2f}%\".format(results[RESNET50][0], results[RESNET50][1] * 100.0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Salvar modelo\n",
        "save_model(resnet_model, model_paths[RESNET50])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MjOx3GN8xtW7"
      },
      "source": [
        "### InceptionV3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Mapeamento dos conjuntos\n",
        "def inception_preprocess_dataset(images, labels): \n",
        "    return inception_preprocess_input(images), labels\n",
        "inception_train_data = train_data.map(inception_preprocess_dataset)\n",
        "inception_val_data = val_data.map(inception_preprocess_dataset)\n",
        "inception_test_data = test_data.map(inception_preprocess_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Nova arquitetura InceptionV3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C_tGWKI-xuW9",
        "outputId": "1b6f4648-7cf0-47cf-a2e9-522b6f4131d3"
      },
      "outputs": [],
      "source": [
        "# Modelo original\n",
        "base_model = InceptionV3(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "\n",
        "# Adição de camadas\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "outputs = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "# Novo modelo\n",
        "inception_model = Model(inputs=base_model.input, outputs=outputs)\n",
        "\n",
        "# Congelamento das camadas convolucionais (para treinar somente as camadas superiores)\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Compilação\n",
        "loss_function = SparseCategoricalCrossentropy()\n",
        "model_optimizer = Adam(learning_rate = 0.00025, clipnorm = 1.0)\n",
        "inception_model.compile(optimizer=model_optimizer, loss=loss_function, metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ehfdgazy6JEw",
        "outputId": "b04c086c-ea77-4d27-b939-b5394726ee58"
      },
      "outputs": [],
      "source": [
        "# Treino das camadas superiores\n",
        "epochs = 8\n",
        "inception_model.fit (\n",
        "    inception_train_data, \n",
        "    validation_data = inception_val_data, \n",
        "    epochs = epochs, \n",
        ")\n",
        "save_model(inception_model, model_backup_paths[INCEPTIONV3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ReuaIZFJ9SJD",
        "outputId": "c3b8b297-3502-49ff-f877-8c1dbf99ac7e"
      },
      "outputs": [],
      "source": [
        "# Visualização das camadas (para escolher até onde descongelar)\n",
        "for i, layer in enumerate(base_model.layers):\n",
        "   print(i, layer.name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "43dtWMAS6fvs",
        "outputId": "d6241053-2d82-4883-c3d3-1181a4b195ca"
      },
      "outputs": [],
      "source": [
        "# Descongelamento das orimeiras camadas\n",
        "for layer in inception_model.layers[:249]:\n",
        "   layer.trainable = False\n",
        "for layer in inception_model.layers[249:]:\n",
        "   layer.trainable = True\n",
        "\n",
        "# Recompilação\n",
        "loss_function = SparseCategoricalCrossentropy()\n",
        "model_optimizer = SGD(learning_rate=0.0001, momentum=0.9)\n",
        "inception_model.compile(optimizer=model_optimizer, loss=loss_function, metrics=['accuracy'])\n",
        "\n",
        "# Treino\n",
        "epochs = 32\n",
        "inception_model.fit (\n",
        "    inception_train_data, \n",
        "    validation_data = inception_val_data, \n",
        "    epochs = epochs, \n",
        ")\n",
        "save_model(inception_model, model_backup_paths[INCEPTIONV3])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Carregamento de um modelo InceptionV3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Carregamento do modelo\n",
        "inception_model = load_model(model_paths[INCEPTIONV3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Treino\n",
        "epochs = 8\n",
        "inception_model.fit (\n",
        "    inception_train_data, \n",
        "    validation_data = inception_val_data, \n",
        "    epochs = epochs, \n",
        ")\n",
        "save_model(inception_model, model_backup_paths[INCEPTIONV3])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Teste da InceptionV3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DHCF-evW6qyy",
        "outputId": "3cf28b8c-5d51-46a3-d663-fbe3de2bf40d"
      },
      "outputs": [],
      "source": [
        "# Teste\n",
        "results[INCEPTIONV3] = inception_model.evaluate(inception_test_data)\n",
        "print(\"loss = {:.2f}; accuracy = {:.2f}%\".format(results[INCEPTIONV3][0], results[INCEPTIONV3][1] * 100.0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Salvar modelo\n",
        "save_model(inception_model, model_paths[INCEPTIONV3])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KFKEoobpC-cn"
      },
      "source": [
        "# Resultados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405
        },
        "id": "yCX6iqPvDFGl",
        "outputId": "47130438-8fbf-4c6d-e3e4-cae1d9e2207d"
      },
      "outputs": [],
      "source": [
        "# Preparação\n",
        "plt.figure(figsize=(10,6))\n",
        "numeric_results = np.array(list(results.values()))\n",
        "labels = [\"Dense\", \"Convolutional\", \"Xception\", \"ResNet50\", \"InceptionV3\"]\n",
        "x = np.arange(numeric_results.shape[0])\n",
        "\n",
        "# Barras\n",
        "plt.bar(x-0.2, numeric_results[:,0], 0.4, label = 'Loss')\n",
        "plt.bar(x+0.2, numeric_results[:,1], 0.4, label = 'Accuracy')\n",
        "\n",
        "# Eixos\n",
        "plt.xticks(x, labels)\n",
        "plt.xlabel(\"NN Architecture\")\n",
        "plt.ylabel(\"Results\")\n",
        "plt.title(\"Metric results for different NN architectures\")\n",
        "plt.legend()\n",
        "\n",
        "# Display\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xxPUocFJOfJG"
      },
      "source": [
        "---\n",
        "\n",
        "ESCREVER SOBRE OS RESULTADOS AQUI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KNt2wfuWC8zc"
      },
      "source": [
        "# Visualização\n",
        "Requer o treinamento do modelo InceptionV3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "BB17_q1Q-PrZ",
        "outputId": "a1751ae4-4201-47fb-b4f7-1aa072db9bd4"
      },
      "outputs": [],
      "source": [
        "# Dependências\n",
        "from keras.applications.inception_v3 import decode_predictions, preprocess_input\n",
        "\n",
        "# Imagem a ser utilizada\n",
        "IMAGE_PATH = \"./data/raw-img/elefante/e83cb60828f5043ed1584d05fb1d4e9fe777ead218ac104497f5c978a4eebdbd_640.jpg\"\n",
        "\n",
        "# Modelo auxiliar para visualizar as decisões\n",
        "base_model = InceptionV3(input_tensor=input_tensor, weights='imagenet')\n",
        "view_model = Model(inputs=base_model.inputs, outputs=base_model.layers[1].output)\n",
        "\n",
        "# Imagem a ser utilizada\n",
        "image = tf.keras.preprocessing.image.load_img(IMAGE_PATH, target_size=IMAGE_SIZE)\n",
        "display(image)\n",
        "image = tf.keras.preprocessing.image.img_to_array(image)\n",
        "image = preprocess_input(image)\n",
        "image = np.expand_dims(image, axis=0)\n",
        "preds = base_model.predict(image)\n",
        "print(decode_predictions(preds, top=3)[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extração de características e visualização\n",
        "features = view_model.predict(image)\n",
        "fig = plt.figure(figsize=(20,15))\n",
        "for i in range(1,features.shape[3]+1):\n",
        "    plt.subplot(8,8,i)\n",
        "    plt.axis(\"off\")\n",
        "    plt.imshow(features[0,:,:,i-1] , cmap='gray')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "wKQ52y8A5425",
        "outputId": "5406a6b5-b8dd-4706-d6a3-5943c896b150"
      },
      "outputs": [],
      "source": [
        "# Extração das camadas convolucionais e construção do modelo\n",
        "conv_layers = []\n",
        "for i, layer in enumerate(base_model.layers):\n",
        "    if \"conv\" in layer.name:\n",
        "        conv_layers.append(i)\n",
        "head = conv_layers[:8] # Primeiras 8 camadas\n",
        "tail = conv_layers[-8:] # Últimas 8 camadas\n",
        "conv_layers = head + tail\n",
        "outputs = [inception_model.layers[i].output for i in conv_layers]\n",
        "view_model = Model(inputs=inception_model.inputs, outputs=outputs)\n",
        "\n",
        "# Visualização\n",
        "feature_map = view_model.predict(image)\n",
        "for i, fmap in zip(conv_layers, feature_map):\n",
        "    fig = plt.figure(figsize=(20,15))\n",
        "    fig.suptitle(\"BLOCK_{}\".format(i) , fontsize=20)\n",
        "    for i in range(1,features.shape[3]+1):\n",
        "        plt.subplot(8,8,i)\n",
        "        plt.imshow(fmap[0,:,:,i-1] , cmap='gray')   \n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zeJJub_t7ZUp"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "bq6gfFOexSXZ",
        "qMKXShwTxlUg"
      ],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.9.12 ('standard_environment')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "8e287d07a5b23f74e16f88f4098195598a7184e1f27f2a36b009c5ead2189863"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
